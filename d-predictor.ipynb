{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# only for Google Colab\n",
    "!mkdir data\n",
    "!mkdir checkpoints\n",
    "\n",
    "!wget -O data/data.zip 'https://docs.google.com/uc?export=download&id=1g6TxegO19bZCWIeuG3hSelPtglmbLWoE' --no-check-certificate\n",
    "!unzip data/* -d data/"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import math\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "npy_data_path = os.path.join('data', 'AAPL*.npy')\n",
    "files_to_load = sorted(glob.glob(npy_data_path))\n",
    "\n",
    "if not files_to_load:\n",
    "    sys.exit('Files to load not found')\n",
    "\n",
    "d_num_layers = 6  # Price, Ordered volume, Filled volume, Canceled volume, Pending volume, Time index\n",
    "d_num_price_levels = 10 * 2 * 2  # price level ($10) per 50 cents per level (*2) per side (*2)\n",
    "d_minutes_per_day = int(6.5 * 60)  # 6 hours 30 minutes of data per trading session, from 9:30 to 16:00\n",
    "d_total_minutes = d_minutes_per_day * len(files_to_load)\n",
    "\n",
    "d = np.zeros((d_num_layers, d_num_price_levels, d_total_minutes), np.float32)\n",
    "\n",
    "load_pointer = 0\n",
    "for file in files_to_load:\n",
    "    d[:, :, load_pointer:load_pointer + d_minutes_per_day] = np.load(file)\n",
    "    load_pointer += d_minutes_per_day\n",
    "\n",
    "\n",
    "# make X and y\n",
    "\n",
    "d_pointer = 0\n",
    "x_block_length = 10 # in minutes\n",
    "y_block_length = 1 # in minutes\n",
    "highest_bid_position = int(d_num_price_levels / 2)\n",
    "error_severity_multiplier = 1000\n",
    "X_y_pointer = 0\n",
    "\n",
    "X_y_entries_count = d_total_minutes - x_block_length  # d_pointer += 1\n",
    "\n",
    "X = np.zeros((X_y_entries_count, d_num_price_levels * x_block_length * d_num_layers), np.float32)\n",
    "y = np.zeros((X_y_entries_count, 3), np.float32)\n",
    "\n",
    "while d_pointer + x_block_length + y_block_length < d_total_minutes:\n",
    "    new_X = d[:, :, d_pointer:d_pointer + x_block_length]\n",
    "\n",
    "    last_X_price = new_X[0, highest_bid_position, -1]\n",
    "    raw_new_y = d[0, highest_bid_position, d_pointer + x_block_length + y_block_length]\n",
    "\n",
    "    if raw_new_y - last_X_price > 0:\n",
    "        new_y = np.array([0, 0, 1], np.float32)\n",
    "    elif raw_new_y - last_X_price < 0:\n",
    "        new_y = np.array([1, 0, 0], np.float32)\n",
    "    else:\n",
    "        new_y = np.array([0, 1, 0], np.float32)\n",
    "\n",
    "    X[X_y_pointer] = new_X.flatten()\n",
    "    y[X_y_pointer] = new_y\n",
    "\n",
    "    X_y_pointer += 1\n",
    "    d_pointer += 1\n",
    "\n",
    "\n",
    "# normalize data with 0 and non-0 responses\n",
    "X_with_minus_one_answer = X[y[:, 0] == 1]\n",
    "y_with_minus_one_answer = y[y[:, 0] == 1]\n",
    "X_with_zero_answer = X[y[:, 1] == 1]\n",
    "y_with_zero_answer = y[y[:, 1] == 1]\n",
    "X_with_one_answer = X[y[:, 2] == 1]\n",
    "y_with_one_answer = y[y[:, 2] == 1]\n",
    "\n",
    "X_with_minus_one_answer, y_with_minus_one_answer = shuffle(X_with_minus_one_answer, y_with_minus_one_answer)\n",
    "X_with_zero_answer, y_with_zero_answer = shuffle(X_with_zero_answer, y_with_zero_answer)\n",
    "X_with_one_answer, y_with_one_answer = shuffle(X_with_one_answer, y_with_one_answer)\n",
    "\n",
    "min_answer_group_length = min(len(y_with_minus_one_answer), len(y_with_zero_answer), len(y_with_one_answer))\n",
    "\n",
    "X = np.concatenate((\n",
    "    X_with_minus_one_answer[:min_answer_group_length],\n",
    "    X_with_zero_answer[:min_answer_group_length],\n",
    "    X_with_one_answer[:min_answer_group_length]\n",
    "))\n",
    "y = np.concatenate((\n",
    "    y_with_minus_one_answer[:min_answer_group_length],\n",
    "    y_with_zero_answer[:min_answer_group_length],\n",
    "    y_with_one_answer[:min_answer_group_length]\n",
    "))\n",
    "\n",
    "X, y = shuffle(X, y)\n",
    "\n",
    "train_data_pointer = len(X) - int(len(X) / 10) # 10%\n",
    "X_train = X[0:train_data_pointer]\n",
    "y_train = y[0:train_data_pointer]\n",
    "X_test = X[train_data_pointer:-1]\n",
    "y_test = y[train_data_pointer:-1]\n",
    "\n",
    "def get_accuracy():\n",
    "    p_indexes = np.argmax(predictions, axis=1)\n",
    "    y_indexes = np.argmax(y_test, axis=1)\n",
    "\n",
    "    true_answers = len(np.where(p_indexes == y_indexes)[0])\n",
    "\n",
    "    y_sub_1 = len(np.where(y_test[:, 0] == 1)[0])\n",
    "    y_0 = len(np.where(y_test[:, 1] == 1)[0])\n",
    "    y_1 = len(np.where(y_test[:, 2] == 1)[0])\n",
    "\n",
    "    true_sub_1_answers = len(np.intersect1d( np.where(np.argmax(y_test, axis=1) == 0)[0], np.where(np.argmax(predictions, axis=1) == 0)[0] ))\n",
    "    true_0_answers = len(np.intersect1d( np.where(np.argmax(y_test, axis=1) == 1)[0], np.where(np.argmax(predictions, axis=1) == 1)[0] ))\n",
    "    true_1_answers = len(np.intersect1d( np.where(np.argmax(y_test, axis=1) == 2)[0], np.where(np.argmax(predictions, axis=1) == 2)[0] ))\n",
    "\n",
    "    print('Total true answers: ' + str(math.floor(true_answers * 100 / len(predictions))) + '%')\n",
    "    print('-1 true answers: ' + str(math.floor(true_sub_1_answers * 100 / y_sub_1 )) + '%')\n",
    "    print('0 true answers: ' + str(math.floor(true_0_answers * 100 / y_0 )) + '%')\n",
    "    print('1 true answers: ' + str(math.floor(true_1_answers * 100 / y_1 )) + '%')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(2400, activation=lambda x: tf.nn.leaky_relu(x, alpha=0.01)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2400, activation=lambda x: tf.nn.leaky_relu(x, alpha=0.01)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(600, activation=lambda x: tf.nn.leaky_relu(x, alpha=0.01)))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Dense(50, activation=lambda x: tf.nn.leaky_relu(x, alpha=0.01)))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "best_checkpoint_path = os.path.join('checkpoints', 'best_weights.hdf5')\n",
    "\n",
    "batch_size = 4096\n",
    "train_data_slice = (len(X_train) // batch_size) * batch_size\n",
    "test_data_slice = (len(X_test) // batch_size) * batch_size\n",
    "\n",
    "model.fit(x=X_train[:train_data_slice], y=y_train[:train_data_slice],\n",
    "          validation_data=(X_test[:test_data_slice], y_test[:test_data_slice]),\n",
    "          batch_size=batch_size, epochs=1000,\n",
    "          callbacks=[\n",
    "              ModelCheckpoint(\n",
    "                  best_checkpoint_path,\n",
    "                  monitor='accuracy',\n",
    "                  save_best_only=True,\n",
    "                  verbose=1,\n",
    "                  save_weights_only=True\n",
    "              )\n",
    "          ],\n",
    "          )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.DataFrame(model.history.history).plot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.load_weights(best_checkpoint_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "get_accuracy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mean_absolute_error(y_test, predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Our predictions\n",
    "# plt.scatter(y_test,predictions)\n",
    "plt.figure(figsize=(20,12))\n",
    "plt.plot(predictions, 'purple')\n",
    "\n",
    "# Perfect predictions\n",
    "plt.plot(y_test, 'green')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,12))\n",
    "plt.plot(y_train, 'green')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,12))\n",
    "plt.plot(predictions, 'green')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}