{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "npy_data_path = os.path.join('data', 'AAPL*.npy')\n",
    "files_to_load = sorted(glob.glob(npy_data_path))\n",
    "\n",
    "if not files_to_load:\n",
    "    sys.exit('Files to load not found')\n",
    "\n",
    "d_num_layers = 6  # Price, Ordered volume, Filled volume, Canceled volume, Pending volume, Time index\n",
    "d_num_price_levels = 10 * 2 * 2  # price level ($10) per 50 cents per level (*2) per side (*2)\n",
    "d_minutes_per_day = int(6.5 * 60)  # 6 hours 30 minutes of data per trading session, from 9:30 to 16:00\n",
    "d_total_minutes = d_minutes_per_day * len(files_to_load)\n",
    "\n",
    "d = np.zeros((d_num_layers, d_num_price_levels, d_total_minutes), np.float32)\n",
    "\n",
    "load_pointer = 0\n",
    "for file in files_to_load:\n",
    "    d[:, :, load_pointer:load_pointer + d_minutes_per_day] = np.load(file)\n",
    "    load_pointer += d_minutes_per_day\n",
    "\n",
    "\n",
    "# make X and y\n",
    "\n",
    "d_pointer = 0\n",
    "x_block_length = 10 # in minutes\n",
    "y_block_length = 1 # in minutes\n",
    "highest_bid_position = int(d_num_price_levels / 2)\n",
    "error_severity_multiplier = 1000\n",
    "X_y_pointer = 0\n",
    "X_y_entries_count = int(d_total_minutes / x_block_length) - 1\n",
    "\n",
    "\n",
    "X = np.zeros((X_y_entries_count, d_num_price_levels, x_block_length, d_num_layers), np.float32)\n",
    "y = np.zeros((X_y_entries_count, 1), np.float32)\n",
    "\n",
    "while d_pointer + x_block_length < d_total_minutes:\n",
    "    new_X = d[:, :, d_pointer:d_pointer + x_block_length]\n",
    "\n",
    "    last_X_price = new_X[0, highest_bid_position, -1]\n",
    "    raw_new_y = d[0, highest_bid_position, d_pointer + x_block_length + y_block_length]\n",
    "    new_y = (raw_new_y - last_X_price) * error_severity_multiplier\n",
    "\n",
    "    X[X_y_pointer] = new_X.transpose(1, 2, 0)\n",
    "    y[X_y_pointer] = new_y\n",
    "\n",
    "    X_y_pointer += 1\n",
    "    d_pointer += x_block_length\n",
    "    # d_pointer += 60 # 5 min\n",
    "\n",
    "\n",
    "train_data_pointer = len(X) - int(len(X) / 10) # 10%\n",
    "\n",
    "X_train = X[0:train_data_pointer]\n",
    "y_train = y[0:train_data_pointer]\n",
    "\n",
    "X_test = X[train_data_pointer:-1]\n",
    "y_test = y[train_data_pointer:-1]\n",
    "\n",
    "# X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2400, activation=lambda x: tf.nn.leaky_relu(x, alpha=0.01)))\n",
    "model.add(Dense(2400, activation=lambda x: tf.nn.leaky_relu(x, alpha=0.01)))\n",
    "model.add(Dense(1200, activation=lambda x: tf.nn.leaky_relu(x, alpha=0.01)))\n",
    "model.add(Dense(600, activation=lambda x: tf.nn.leaky_relu(x, alpha=0.01)))\n",
    "model.add(Dense(300, activation=lambda x: tf.nn.leaky_relu(x, alpha=0.01)))\n",
    "model.add(Dense(50, activation=lambda x: tf.nn.leaky_relu(x, alpha=0.01)))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_data_slice = (len(X_train) // batch_size) * batch_size\n",
    "test_data_slice = (len(X_test) // batch_size) * batch_size\n",
    "\n",
    "model.fit(x=X_train[:train_data_slice], y=y_train[:train_data_slice],\n",
    "          validation_data=(X_test[:test_data_slice], y_test[:test_data_slice]),\n",
    "          batch_size=batch_size, epochs=200)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.DataFrame(model.history.history).plot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mean_absolute_error(y_test, predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Our predictions\n",
    "# plt.scatter(y_test,predictions)\n",
    "plt.figure(figsize=(20,12))\n",
    "plt.plot(predictions, 'purple')\n",
    "\n",
    "# Perfect predictions\n",
    "plt.plot(y_test, 'green')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,12))\n",
    "plt.plot(y_train, 'green')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,12))\n",
    "plt.plot(predictions, 'green')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# plt.imsave('layer_0.png', d[0], cmap='hot')\n",
    "# plt.imsave('layer_1.png', d[1], cmap='hot')\n",
    "# plt.imsave('layer_2.png', d[2], cmap='hot')\n",
    "# plt.imsave('layer_3.png', d[3], cmap='hot')\n",
    "# plt.imsave('layer_4.png', d[4], cmap='hot')\n",
    "# plt.imsave('layer_5.png', d[5], cmap='hot')\n",
    "#\n",
    "# d.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# scaling\n",
    "\n",
    "# v_min = X_train.min(axis=(0, 1, 2, 3), keepdims=True)\n",
    "# v_max = X_train.max(axis=(0, 1, 2, 3), keepdims=True)\n",
    "#\n",
    "# X_train = (X_train - v_min)/(v_max - v_min)\n",
    "# X_test = (X_test - v_min)/(v_max - v_min)\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "#\n",
    "# n_train_samples, n_train_x, n_train_y, n_train_z = X_train.shape\n",
    "# X_train = X_train.reshape((n_train_samples, n_train_x * n_train_y * n_train_z))\n",
    "#\n",
    "# n_test_samples, n_test_x, n_test_y, n_test_z = X_test.shape\n",
    "# X_test = X_test.reshape((n_test_samples, n_test_x * n_test_y * n_test_z))\n",
    "#\n",
    "# scaler.fit(X_train)\n",
    "#\n",
    "# X_train = scaler.transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "#\n",
    "# X_train = X_train.reshape((n_train_samples, n_train_x, n_train_y, n_train_z))\n",
    "# X_test = X_test.reshape((n_test_samples, n_test_x, n_test_y, n_test_z))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}